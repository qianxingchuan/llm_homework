{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ba5ff69-5fec-4cfe-9cfe-98e5ac3243fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-22 19:16:16.267895: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-22 19:16:16.290009: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1745320576.314752  169751 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1745320576.322440  169751 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1745320576.343018  169751 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745320576.343037  169751 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745320576.343039  169751 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745320576.343041  169751 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-22 19:16:16.349631: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58a3bf5147f44a8eb8efe90632a6f004",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [config.json]:   0%|          | 0.00/801 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "247dd0ced0c24fbf95838df09a604af5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [configuration.json]:   0%|          | 0.00/76.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65740fd8d2d94f8fa9c128b313e3aa65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [onnx/model.onnx]:   0%|          | 0.00/604k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1b4be1c463140c3b5f8785df689c2f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [onnx/model.onnx_data]:   0%|          | 0.00/2.09G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82b795f7b3864075976549143d8a45be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [model.safetensors]:   0%|          | 0.00/2.09G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7c4ba7b4cdc47ceb101e854fab6487c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [pytorch_model.bin]:   0%|          | 0.00/2.09G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fdefb11b2be4a5b8d86ec9ba3f81ec9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [README.md]:   0%|          | 0.00/33.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e56a256831c49a5b7edf466c1eaac55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [sentencepiece.bpe.model]:   0%|          | 0.00/4.83M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e3d51da7e3d4d0a96c53076265fa159",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [special_tokens_map.json]:   0%|          | 0.00/279 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1616e94ecee14784b1fa139bcd934d9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [tokenizer.json]:   0%|          | 0.00/16.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35258a30f6444be4b883b45f60b43c34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [tokenizer_config.json]:   0%|          | 0.00/443 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#模型下载\n",
    "from modelscope import snapshot_download\n",
    "model_dir = snapshot_download('BAAI/bge-reranker-large', cache_dir='/root/autodl-tmp/models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51fe6363-8f2e-4cdb-9815-ab408b12f244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.9538], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('/root/autodl-tmp/models/BAAI/bge-reranker-large')\n",
    "model = AutoModelForSequenceClassification.from_pretrained('/root/autodl-tmp/models/BAAI/bge-reranker-large')\n",
    "model.eval()\n",
    "\n",
    "pairs = [['what is panda?', 'The giant panda is a bear species endemic to China.']]\n",
    "inputs = tokenizer(pairs, padding=True, truncation=True, return_tensors='pt')\n",
    "scores = model(**inputs).logits.view(-1).float()\n",
    "print(scores)  # 输出相关性分数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92b5eef6-bb6b-4f90-8318-2b3a73ab1aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 4.9538, -0.4951, -9.4803], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "pairs = [\n",
    "    ['what is panda?', 'The giant panda is a bear species endemic to China.'],  # 高相关\n",
    "    ['what is panda?', 'Pandas are cute.'],                                     # 中等相关\n",
    "    ['what is panda?', 'The Eiffel Tower is in Paris.']                        # 不相关\n",
    "]\n",
    "inputs = tokenizer(pairs, padding=True, truncation=True, return_tensors='pt')\n",
    "scores = model(**inputs).logits.view(-1).float()\n",
    "print(scores)  # 输出相关性分数"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
