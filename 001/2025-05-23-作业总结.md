
## 作业总结
本次作业，我本地部署ollama，把之前的作业做了一些调整，做了一个中间层，既可以调用dashscope，也可以调用本地ollama，也都解决了接口字段兼容的问题。

但是现在在调用ollama的时候，对于function call的触发，就没有完美跑出结果，不是一次返回多个function call，就是一个function call都没有。我调整了各种提示词，依然不能通过ollama得到像dashscope那样准确完美的结果。

#### 主要几个问题：

1、ollama运行的大模型，对于function call的处理，我如果使用ollama这个python依赖，是不是没有办法调整很多细节？推荐的方式应该是怎样的？使用ollama的python依赖库？还是自己用requests去解析模型交互文本？

2、当前调用ollama的这个qwen3:0.6b或者是1.7b，提示词如下,这种简单的场景，我希望可以优化调整提示词，用这种小参数模型达到目标：
```
        你是一个专业的天气助手，仅能处理与天气相关的问题，其他问题需拒绝回答。
        你可以调用我提供的一些tools，但是必须每次只能让我调用一次，
        比如：
        你需要“今天”的值，你可以返回:
        <tool>
        {"name":"weather_tools.today","arguments":{}}
        </tool>
        你需要“杭州”这个城市对应的locationId，你可以返回：
        <tool>
        {"name":"weather_tools.get_location_id_by_city_name","arguments":{"city_name":"杭州"}}
        </tool>
        当需要天气的具体信息，可以返回：
        <tool>
        {"name": "weather_tools.get_current_weather", "arguments": {"locationId": "101280101", "date": "2025-05-23"}}
        </tool>
        我每次只能处理一个tool标签
```

3、 ollma这个调试，太难受了，是不是每次切换一下模型，这种调试的过程都得来一遍？

4、 对于模型的回答的随机性，ollama的python依赖，我怎么指定temperaure？

5、对于这个prompt，我其实现在有疑问就是，参数大起到的作用如果是更聪明，是怎么做到更聪明的？后面的这个模型，对我来说是完全黑盒的。
小参数的模型是不是一定就不聪明？我们可以通过哪些手段能让小参数模型更符合我们的业务要求？
是不是小参数模型，就一定是一无是处？

@冰冰老师回复：
```
1、小模型的优势：参数少、轻量化特性，适合部署在手机、IoT 设备等计算资源有限的场景，能提供较高的运行效率和速度；但适合非常特定垂直的场景，比如就是解析某一个表单，只做这几件事就够

2、大模型之所以更好：因为Scaling Law的发现，模型性能随参数量和训练数据量同步增长，大模型能更充分挖掘海量数据中的规律，避免小模型的“能力瓶颈” https://zhuanlan.zhihu.com/p/667489780
但是scaling law据说也开始逐步放缓了，所以现在你看都不是特别强调参数量了

用一套问题+评分模型，对应找多个模型回复。这个的难点在于：1、问题集的建立；2、评分模型的建立

关于“微调”，可以让大模型理解复杂的逻辑么？
可能比较难，达不到复杂程度；用我们研发的话来说，微调不是终极最佳方案，容易拟合、容易费了老大劲效果不咋地。。

AI开发的痛点就在这里！！！！
有一个底层逻辑就是关于模型和模型的差异点到底在哪儿，换一个模型如果还不行，那是不是再换一个？一个一个试，就太痛苦了。为什么同样的prompt在a模型不行，但是b模型就可以了呢。
```

## 自己的思考：

这个地方，我其实是可以调优的，比如这个天气的询问，用户问“今天杭州天气怎样？”，通过提示词，是可以给我一个function call，调用today函数，然后不知道为什么，调整了提示词，function call就丢了。所以我觉得可能也跟python的ollama依赖库的处理也有关系，所以这个地方我才会问，是不是在工程化处理的时候，大家会更倾向于用requests来解析原有内容？
